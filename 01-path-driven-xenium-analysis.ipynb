{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f7be38",
   "metadata": {},
   "source": [
    "# Path-Driven Xenium Analysis Notebook\n",
    "\n",
    "This notebook replicates the core analysis from `/Users/chrislangseth/work/spatialist/intership1/00-batch-processing.ipynb` and is designed so you only need to change the dataset path.\n",
    "\n",
    "## How to use\n",
    "1. Open this notebook in Jupyter Lab or VS Code.\n",
    "2. Run cells from top to bottom.\n",
    "3. In **Step 1**, set `DATA_DIR` to your new dataset folder.\n",
    "4. Check generated outputs under `OUT_DIR`.\n",
    "\n",
    "## Expected input folder layout\n",
    "- `DATA_DIR/`\n",
    "  - `output-.../`\n",
    "    - `cell_feature_matrix.h5`\n",
    "    - `cells.csv.gz`\n",
    "\n",
    "If your run folder names differ, adjust `RUN_PREFIX` in Step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6308e",
   "metadata": {},
   "source": [
    "## Step 0: Imports and plotting setup\n",
    "\n",
    "This step loads the analysis libraries (`scanpy`, `pandas`, `seaborn`, etc.) and configures plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb31df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d297041",
   "metadata": {},
   "source": [
    "## Step 1: Configure your paths and parameters\n",
    "\n",
    "- `DATA_DIR`: your new dataset path.\n",
    "- `OUT_DIR`: where all outputs will be saved.\n",
    "- `RUN_PREFIX`: run folder naming pattern.\n",
    "- `SAMPLE_ID_SPLIT` and `SAMPLE_ID_INDEX`: controls how `sample_id` is extracted from run names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED: change this to your new dataset location.\n",
    "DATA_DIR = Path('/absolute/path/to/new/dataset').expanduser().resolve()\n",
    "\n",
    "# Optional: change this output directory.\n",
    "OUT_DIR = Path('/absolute/path/to/output').expanduser().resolve()\n",
    "\n",
    "# Run folder prefix (reference workflow used output-*).\n",
    "RUN_PREFIX = 'output-'\n",
    "\n",
    "# Extract sample_id from run name, e.g. run.split('__')[2]\n",
    "SAMPLE_ID_SPLIT = '__'\n",
    "SAMPLE_ID_INDEX = 2\n",
    "\n",
    "# Clustering / preprocessing parameters (same spirit as reference notebook)\n",
    "MIN_COUNTS = 50\n",
    "MIN_GENES = 15\n",
    "TARGET_SUM = 100\n",
    "N_NEIGHBORS = 15\n",
    "N_PCS = 30\n",
    "UMAP_MIN_DIST = 0.1\n",
    "LEIDEN_RESOLUTIONS = [0.1, 0.5, 1, 1.5, 2]\n",
    "\n",
    "DATA_OUT_DIR = OUT_DIR / 'data'\n",
    "QC_DIR = OUT_DIR / 'xenium_qc'\n",
    "DATA_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "QC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'DATA_DIR: {DATA_DIR}')\n",
    "print(f'OUT_DIR : {OUT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f22dd5",
   "metadata": {},
   "source": [
    "## Step 2: Discover and validate run folders\n",
    "\n",
    "This step finds all run folders (for example `output-*`) and checks each has:\n",
    "- `cell_feature_matrix.h5`\n",
    "- `cells.csv.gz`\n",
    "\n",
    "Invalid runs are skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_DIR.is_dir():\n",
    "    raise NotADirectoryError(f'Invalid DATA_DIR: {DATA_DIR}')\n",
    "\n",
    "runs = [p for p in sorted(DATA_DIR.iterdir()) if p.is_dir() and p.name.startswith(RUN_PREFIX)]\n",
    "if not runs:\n",
    "    raise FileNotFoundError(f'No run directories starting with {RUN_PREFIX!r} in {DATA_DIR}')\n",
    "\n",
    "valid_runs = []\n",
    "for run in runs:\n",
    "    h5_path = run / 'cell_feature_matrix.h5'\n",
    "    cell_info_path = run / 'cells.csv.gz'\n",
    "    if h5_path.exists() and cell_info_path.exists():\n",
    "        valid_runs.append(run)\n",
    "    else:\n",
    "        print(f'Skipping {run.name}: missing required files')\n",
    "\n",
    "if not valid_runs:\n",
    "    raise RuntimeError('No valid runs found with required files.')\n",
    "\n",
    "print(f'Found {len(valid_runs)} valid run(s):')\n",
    "for r in valid_runs:\n",
    "    print(' -', r.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f317a",
   "metadata": {},
   "source": [
    "## Step 3: Load each run and concatenate into one AnnData object\n",
    "\n",
    "For each run:\n",
    "1. Read the expression matrix from `cell_feature_matrix.h5`.\n",
    "2. Read cell metadata from `cells.csv.gz`.\n",
    "3. Attach metadata to `ad_int.obs`.\n",
    "4. Add `run` column and append to list.\n",
    "\n",
    "Finally, all runs are concatenated into `ad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6685a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_list = []\n",
    "\n",
    "for run in valid_runs:\n",
    "    print(f'Loading: {run.name}')\n",
    "    ad_int = sc.read_10x_h5(str(run / 'cell_feature_matrix.h5'))\n",
    "    cell_info = pd.read_csv(run / 'cells.csv.gz', index_col=0)\n",
    "\n",
    "    if len(cell_info) != ad_int.n_obs:\n",
    "        raise ValueError(\n",
    "            f'Row mismatch for {run.name}: cells.csv.gz={len(cell_info)} vs matrix={ad_int.n_obs}'\n",
    "        )\n",
    "\n",
    "    ad_int.obs = cell_info\n",
    "    ad_int.obs['run'] = run.name\n",
    "    ad_list.append(ad_int)\n",
    "\n",
    "ad = sc.concat(ad_list)\n",
    "ad.layers['counts'] = ad.X.copy()\n",
    "\n",
    "print(ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208ddfb",
   "metadata": {},
   "source": [
    "## Step 4: Compute QC metrics and create `sample_id`\n",
    "\n",
    "- `sc.pp.calculate_qc_metrics` adds standard QC columns such as `total_counts` and `n_genes_by_counts`.\n",
    "- `sample_id` is parsed from `run` name. If parsing fails, run name itself is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b30f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.calculate_qc_metrics(ad, percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "def infer_sample_id(run_name: str, split_token: str = SAMPLE_ID_SPLIT, split_index: int = SAMPLE_ID_INDEX) -> str:\n",
    "    parts = str(run_name).split(split_token)\n",
    "    if 0 <= split_index < len(parts):\n",
    "        return parts[split_index]\n",
    "    return str(run_name)\n",
    "\n",
    "ad.obs['sample_id'] = ad.obs['run'].astype(str).apply(infer_sample_id)\n",
    "ad.obs['cell_id'] = ad.obs.index.astype(str)\n",
    "\n",
    "display(ad.obs[['run', 'sample_id']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f14bc",
   "metadata": {},
   "source": [
    "## Step 5: Save raw AnnData\n",
    "\n",
    "This saves the merged, unfiltered object so you can reuse it later without reloading all runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = DATA_OUT_DIR / 'raw.h5ad'\n",
    "ad.write(raw_path)\n",
    "print(f'Saved: {raw_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b608e",
   "metadata": {},
   "source": [
    "## Step 6: Generate QC tables and plots\n",
    "\n",
    "This creates the same QC-style outputs as the reference workflow:\n",
    "- `summary_by_run.csv`\n",
    "- Cells-per-run bar plot\n",
    "- Violin plots (`n_genes_by_counts`, `total_counts`)\n",
    "- Counts-vs-genes hexbin\n",
    "- Gene detection outputs (`gene_detection_overall.csv`, top30 bar, run heatmap)\n",
    "- Optional cell area violin plot if an area column exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e37f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_COL = 'run'\n",
    "SAMPLE_COL = 'sample_id'\n",
    "CT_COL = 'cell_types'\n",
    "COUNTS_COL = 'total_counts'\n",
    "NGENES_COL = 'n_genes_by_counts'\n",
    "\n",
    "def _p(series, p):\n",
    "    return float(np.nanpercentile(series, p))\n",
    "\n",
    "agg_dict = {'n_cells': ('cell_id', 'count')}\n",
    "if COUNTS_COL in ad.obs.columns:\n",
    "    agg_dict |= {\n",
    "        'counts_mean': (COUNTS_COL, 'mean'),\n",
    "        'counts_median': (COUNTS_COL, 'median'),\n",
    "        'counts_p10': (COUNTS_COL, lambda x: _p(x, 10)),\n",
    "        'counts_p90': (COUNTS_COL, lambda x: _p(x, 90)),\n",
    "    }\n",
    "if NGENES_COL in ad.obs.columns:\n",
    "    agg_dict |= {\n",
    "        'genes_mean': (NGENES_COL, 'mean'),\n",
    "        'genes_median': (NGENES_COL, 'median'),\n",
    "        'genes_p10': (NGENES_COL, lambda x: _p(x, 10)),\n",
    "        'genes_p90': (NGENES_COL, lambda x: _p(x, 90)),\n",
    "    }\n",
    "\n",
    "summary = ad.obs.groupby(SAMPLE_COL).agg(**agg_dict).sort_values('n_cells', ascending=False)\n",
    "display(summary)\n",
    "summary.to_csv(QC_DIR / 'summary_by_run.csv')\n",
    "\n",
    "plt.figure(figsize=(9, 4.5))\n",
    "sns.barplot(y=summary.index, x=summary['n_cells'], palette='Set3')\n",
    "plt.title('Cells per Xenium run')\n",
    "plt.xlabel('# cells')\n",
    "plt.ylabel('Run')\n",
    "plt.tight_layout()\n",
    "plt.savefig(QC_DIR / 'cells_per_run_bar.png', dpi=200)\n",
    "plt.show()\n",
    "\n",
    "if NGENES_COL in ad.obs.columns:\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    sns.violinplot(data=ad.obs, x=SAMPLE_COL, y=NGENES_COL, inner='quartile', palette='rocket')\n",
    "    plt.title('n_genes_by_counts per run')\n",
    "    plt.xlabel('Run')\n",
    "    plt.ylabel('n_genes_by_counts')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(QC_DIR / 'ngenes_violin.png', dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "if COUNTS_COL in ad.obs.columns:\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    sns.violinplot(data=ad.obs, x=SAMPLE_COL, y=COUNTS_COL, inner='quartile', palette='mako')\n",
    "    plt.title('total_counts per run')\n",
    "    plt.xlabel('Run')\n",
    "    plt.ylabel('total_counts')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(QC_DIR / 'counts_violin.png', dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "if {COUNTS_COL, NGENES_COL}.issubset(ad.obs.columns):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.hexbin(ad.obs[COUNTS_COL], ad.obs[NGENES_COL], gridsize=50, mincnt=1)\n",
    "    plt.xlabel('total_counts')\n",
    "    plt.ylabel('n_genes_by_counts')\n",
    "    plt.title('Counts vs genes (all runs)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(QC_DIR / 'counts_vs_genes_hex.png', dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "if CT_COL in ad.obs.columns:\n",
    "    ct_counts = ad.obs[CT_COL].value_counts()\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    sns.barplot(y=ct_counts.index[:20], x=ct_counts.values[:20], palette='Spectral')\n",
    "    plt.title('Top cell types (all runs)')\n",
    "    plt.xlabel('# cells')\n",
    "    plt.ylabel('cell type')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(QC_DIR / 'celltypes_top20.png', dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "x = ad.X\n",
    "if sparse.issparse(x):\n",
    "    detected = (x > 0).astype(np.int8)\n",
    "    det_overall = np.array(detected.sum(axis=0)).ravel() / ad.n_obs\n",
    "else:\n",
    "    det_overall = np.asarray((x > 0).sum(axis=0)).ravel() / ad.n_obs\n",
    "\n",
    "det_overall_series = pd.Series(det_overall, index=ad.var_names, name='fraction_cells')\n",
    "det_overall_series.sort_values(ascending=False).to_csv(QC_DIR / 'gene_detection_overall.csv')\n",
    "\n",
    "top30 = det_overall_series.sort_values(ascending=False).head(30)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(y=top30.index, x=top30.values, palette='coolwarm')\n",
    "plt.xlabel('fraction of cells detected')\n",
    "plt.ylabel('gene')\n",
    "plt.title('Panel coverage: top 30 genes')\n",
    "plt.tight_layout()\n",
    "plt.savefig(QC_DIR / 'gene_detection_top30.png', dpi=200)\n",
    "plt.show()\n",
    "\n",
    "runs_array = ad.obs[SAMPLE_COL].astype(str).values\n",
    "run_idx = {name: np.where(runs_array == name)[0] for name in np.unique(runs_array)}\n",
    "det_run = {}\n",
    "for run_name, idx in run_idx.items():\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "    if sparse.issparse(x):\n",
    "        sub = x[idx, :]\n",
    "        frac = np.array((sub > 0).sum(axis=0)).ravel() / len(idx)\n",
    "    else:\n",
    "        sub = x[idx, :]\n",
    "        frac = np.asarray((sub > 0).sum(axis=0)).ravel() / len(idx)\n",
    "    det_run[run_name] = frac\n",
    "\n",
    "if det_run:\n",
    "    det_df = pd.DataFrame(det_run, index=ad.var_names).T\n",
    "    sel = det_df.var(axis=0).sort_values(ascending=False).head(40).index\n",
    "    plt.figure(figsize=(min(12, len(sel) * 0.3 + 4), max(4, len(det_df) * 0.35 + 2)))\n",
    "    sns.heatmap(det_df[sel], cmap='rocket', vmin=0, vmax=1, cbar_kws={'label': 'fraction detected'})\n",
    "    plt.title('Gene detection per run (top variable genes)')\n",
    "    plt.xlabel('gene')\n",
    "    plt.ylabel('run')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(QC_DIR / 'gene_detection_heatmap_runs.png', dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "for cand in ['cell_area_um2', 'cell_area', 'area', 'nucleus_area_um2']:\n",
    "    if cand in ad.obs.columns:\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        sns.violinplot(data=ad.obs, x=SAMPLE_COL, y=cand, inner='quartile', palette='PuBuGn')\n",
    "        plt.title(f'{cand} per run')\n",
    "        plt.xlabel('Run')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(QC_DIR / f'{cand}_violin.png', dpi=200)\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "print(f'QC outputs saved to: {QC_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1f79c",
   "metadata": {},
   "source": [
    "## Step 7: Filter, normalize, reduce dimensions, and cluster\n",
    "\n",
    "This performs the same core downstream processing pattern as the reference notebook. Below is the mathematical purpose of each step:\n",
    "\n",
    "1. **Filter low-quality cells**\n",
    "   - Removes extreme low-information points (very low counts/genes) that mostly add technical noise.\n",
    "   - This improves signal-to-noise before any geometry-based methods.\n",
    "\n",
    "2. **Normalize total counts and log-transform**\n",
    "   - Each cell has different sequencing depth (library size), so raw counts are not directly comparable.\n",
    "   - Size-factor normalization rescales each cell to a common total (`target_sum`):\n",
    "     - If cell `i` has total `c_i`, scaled expression is approximately `x_ig * (target_sum / c_i)`.\n",
    "   - `log1p` then compresses dynamic range (`log(1+x)`), reducing dominance of very highly expressed genes.\n",
    "\n",
    "3. **PCA (linear dimensionality reduction)**\n",
    "   - Gene space is very high-dimensional. Distances become unstable in very high dimensions (curse of dimensionality).\n",
    "   - PCA projects data onto orthogonal directions of maximal variance (top eigenvectors of covariance matrix).\n",
    "   - Keeping top PCs denoises data while preserving most biological structure.\n",
    "\n",
    "4. **kNN graph in PC space (`sc.pp.neighbors`)**\n",
    "   - For each cell, connect to its `k` nearest neighbors in PCA space.\n",
    "   - This builds a graph that approximates the local manifold geometry of cell states.\n",
    "   - Downstream methods (UMAP, Leiden) operate on this graph, not raw expression directly.\n",
    "\n",
    "5. **UMAP (nonlinear embedding for visualization)**\n",
    "   - UMAP constructs a fuzzy neighbor graph in high-dimensional space, then finds a 2D embedding with similar fuzzy connectivity.\n",
    "   - It optimizes a cross-entropy-like objective between high-D and low-D neighbor probabilities.\n",
    "   - Main purpose: human-interpretable visualization, not formal statistical inference.\n",
    "\n",
    "6. **Leiden clustering (graph community detection)**\n",
    "   - Leiden partitions the neighbor graph into communities with dense within-cluster edges and sparse between-cluster edges.\n",
    "   - It optimizes a graph quality function (modularity/CPM family) and improves partition connectivity over older methods.\n",
    "   - Resolution controls granularity: lower = broader groups, higher = finer subclusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d7ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_cluster = ad.copy()\n",
    "\n",
    "sc.pp.filter_cells(ad_cluster, min_counts=MIN_COUNTS)\n",
    "sc.pp.filter_cells(ad_cluster, min_genes=MIN_GENES)\n",
    "\n",
    "sc.pp.normalize_total(ad_cluster, target_sum=TARGET_SUM, inplace=True)\n",
    "sc.pp.log1p(ad_cluster)\n",
    "\n",
    "sc.tl.pca(ad_cluster)\n",
    "sc.pp.neighbors(ad_cluster, n_neighbors=N_NEIGHBORS, n_pcs=N_PCS)\n",
    "sc.tl.umap(ad_cluster, min_dist=UMAP_MIN_DIST)\n",
    "\n",
    "for resolution in LEIDEN_RESOLUTIONS:\n",
    "    key = f'leiden_{resolution}'\n",
    "    sc.tl.leiden(ad_cluster, resolution=resolution, key_added=key)\n",
    "    print(f'Computed {key}')\n",
    "\n",
    "ad_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2adf600",
   "metadata": {},
   "source": [
    "## Step 8: UMAP quick checks and marker genes\n",
    "\n",
    "- Plots UMAP colored by sample and final cluster label.\n",
    "- Computes marker genes with `rank_genes_groups`.\n",
    "  - Here we use a t-test per gene (cluster vs rest) to rank genes by differential expression signal.\n",
    "  - This gives interpretable candidate markers for cluster annotation.\n",
    "- Saves clustered object and markers table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_leiden_key = f'leiden_{LEIDEN_RESOLUTIONS[-1]}'\n",
    "\n",
    "sc.pl.umap(ad_cluster, color=['sample_id', final_leiden_key], wspace=0.35)\n",
    "\n",
    "sc.tl.rank_genes_groups(ad_cluster, groupby=final_leiden_key, method='t-test')\n",
    "markers = sc.get.rank_genes_groups_df(ad_cluster, group=None)\n",
    "display(markers.head())\n",
    "\n",
    "clustered_path = DATA_OUT_DIR / 'clustered.h5ad'\n",
    "markers_path = DATA_OUT_DIR / 'markers_by_cluster.csv'\n",
    "\n",
    "ad_cluster.write(clustered_path)\n",
    "markers.to_csv(markers_path, index=False)\n",
    "\n",
    "print(f'Saved clustered AnnData: {clustered_path}')\n",
    "print(f'Saved marker genes   : {markers_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df9b7f",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "- If you get `No run directories...`, verify `DATA_DIR` and `RUN_PREFIX`.\n",
    "- If row mismatch appears in Step 3, one run has inconsistent matrix vs metadata files.\n",
    "- If `sample_id` values look wrong, adjust `SAMPLE_ID_SPLIT` and `SAMPLE_ID_INDEX`.\n",
    "- If `scanpy` is missing, install dependencies in your environment before rerunning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
